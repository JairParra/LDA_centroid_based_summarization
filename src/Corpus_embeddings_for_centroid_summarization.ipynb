{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Word Embeddings for Centroid-based Text Summarization  \n",
    "\n",
    "In this notebook, we will train the word embeddings as proposed in the paper *Centroid-based Text Summarization through Compositionality of Word Embeddings* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import preprocessor # this is the module/wrapper we created. \n",
    "import LDA_extractor\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from preprocessor import spacy_preprocessor \n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# set up preprocessor\n",
    "preproc = spacy_preprocessor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is a sentence.', 'We want to include some stuff.', 'Help!', 'There is not time.']\n"
     ]
    }
   ],
   "source": [
    "# TESTS \n",
    "ex = \"This is a sentence. We want to include some stuff. Help! There is not time.\" \n",
    "sent_tokd = preproc.sent_tokenizer(ex) \n",
    "print(sent_tokd)\n",
    "\n",
    "# Word2Vec()\n",
    "# model = Word2Vec(sent, min_count=1,size= 50,workers=3, window =3, sg = 1)\n",
    "\n",
    "# Want to have this format: \n",
    "input_data = [['This', 'is', 'sentence', 'one'], \n",
    "              ['And', 'this', 'is', 'sentence', 'two']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'str'>\n",
      "Cambodian leader Hun Sen on Friday rejected opposition parties' demands for talks outside the country, accusing them of trying to ``internationalize'' the political crisis. Government and opposition parties have asked King Norodom Sihanouk to host a summit meeting after a series of post-election negotiations between the two opposition groups and Hun Sen's party to form a new government failed. Opposition leaders Prince Norodom Ranariddh and Sam Rainsy, citing Hun Sen's threats to arrest opposition figures after two alleged attempts on his life, said they could not negotiate freely in Cambodia and called for talks at Sihanouk's residence in Beijing. Hun Sen, however, rejected that. ``I would like to make it clear that all meetings related to Cambodian affairs must be conducted in the Kingdom of Cambodia,'' Hun Sen told reporters after a Cabinet meeting on Friday. ``No-one should internationalize Cambodian affairs. It is detrimental to the sovereignty of Cambodia,'' he said. Hun Sen's Cambodian People's Party won 64 of the 122 parliamentary seats in July's elections, short of the two-thirds majority needed to form a government on its own. Ranariddh and Sam Rainsy have charged that Hun Sen's victory in the elections was achieved through widespread fraud. They have demanded a thorough investigation into their election complaints as a precondition for their cooperation in getting the national assembly moving and a new government formed. Hun Sen said on Friday that the opposition concerns over their safety in the country was ``just an excuse for them to stay abroad.'' Both Ranariddh and Sam Rainsy have been outside the country since parliament was ceremonially opened on Sep. 24. Sam Rainsy and a number of opposition figures have been under court investigation for a grenade attack on Hun Sen's Phnom Penh residence on Sep. 7. Hun Sen was not home at the time of the attack, which was followed by a police crackdown on demonstrators contesting Hun Sen's election victory. The Sam Rainsy Party, in a statement released Friday, accused Hun Sen of being ``unwilling to make any compromise'' on negotiations to break the deadlock. ``A meeting outside Cambodia, as suggested by the opposition, could place all parties on more equal footing,'' said the statement. ``But the ruling party refuses to negotiate unless it is able to threaten its negotiating partners with arrest or worse.'' \n"
     ]
    }
   ],
   "source": [
    "PATH = \"../../data_raw/corpus.pkl\"\n",
    "with open(PATH,'rb') as file: \n",
    "    corpus = pickle.load(file) \n",
    "    \n",
    "\"\"\"\n",
    "corpus = {\n",
    "    article_set_id: {\n",
    "        'articles': [\n",
    "            ...list of articles in the set\n",
    "        ],\n",
    "        'summaries': [\n",
    "            ...list of human generated summaries\n",
    "        ]\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "texts = [] \n",
    "for article_set_id in corpus.keys(): \n",
    "    for article in corpus[article_set_id]['articles']: \n",
    "        texts+= [article] \n",
    "    \n",
    "print(type(texts))\n",
    "print(type(texts[0]))\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a list of strings, where each string is a text. We want to tokenize by sentences, and then have one huge list of sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13270\n",
      "Cambodian leader Hun Sen on Friday rejected opposition parties' demands for talks outside the country, accusing them of trying to ``internationalize'' the political crisis.\n"
     ]
    }
   ],
   "source": [
    "sentences = [] \n",
    "\n",
    "# Iterate through every text\n",
    "for text in texts:  \n",
    "    text_sents = preproc.sent_tokenizer(text)  # sent_tokenize that text \n",
    "    sentences += text_sents # append to the collection \n",
    "\n",
    "print(len(sentences)) # we have these many sentences \n",
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to clean all of these sentences. We use the spacy_preprocessor from our preprocessor module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_corpus = preproc.preprocess_texts(\n",
    "                            sentences, \n",
    "                            tags = [\"DET\",\"NUM\",\"SPACE\"], \n",
    "                            custom_filter = [], \n",
    "                            remove_punct = True, \n",
    "                            regex_pattern = '', \n",
    "                            stem=False, \n",
    "                            lemmatize=False, \n",
    "                            join=False, \n",
    "                            min_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['cambodian', 'leader', 'hun', 'sen', 'friday', 'rejected', 'opposition', 'parties', 'demands', 'talks', 'outside', 'country', 'accusing', 'trying', 'internationalize', 'political', 'crisis'], ['government', 'opposition', 'parties', 'asked', 'king', 'norodom', 'sihanouk', 'host', 'summit', 'meeting', 'series', 'post', 'election', 'negotiations', 'opposition', 'groups', 'hun', 'sen', 'party', 'form', 'new', 'government', 'failed']]\n"
     ]
    }
   ],
   "source": [
    "print(clean_corpus[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the actual thing using word2vec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip-gram training \n",
    "\n",
    "Train the model using word2vec. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_gram = Word2Vec(clean_corpus,\n",
    "                     min_count=0, # ignore words that appear less than this \n",
    "                     size= 400, # dimensionality of vectors\n",
    "                     workers=-1, # number of workers \n",
    "                     window=10, # window size \n",
    "                     iter=100, # iteration \n",
    "                     hs = 1, # hierarchical softmax \n",
    "                     negative=10,  # negative sampling? \n",
    "                     sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jairp\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cameras', 0.1896907091140747),\n",
       " ('scrutiny', 0.18311579525470734),\n",
       " ('shooter', 0.17772801220417023),\n",
       " ('bodyguards', 0.17234481871128082),\n",
       " ('taint', 0.17103847861289978),\n",
       " ('role', 0.16631092131137848),\n",
       " ('spared', 0.16630259156227112),\n",
       " ('badly', 0.16278895735740662),\n",
       " ('brand', 0.15966100990772247),\n",
       " ('wrestled', 0.15910710394382477)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_gram.most_similar(\"parties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
